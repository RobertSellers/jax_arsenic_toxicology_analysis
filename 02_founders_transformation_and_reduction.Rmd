---
title: "Founders #2 Dimension reduction"
author:
- name: Robert Sellers
  affiliation: The Jackson Laboratory
date: "`r paste('Last knit on:',format(Sys.time(), '%d %B %Y'))`"
abstract: |
latex_engine: pdflatex
output:
  html_document:
    fig_caption: yes
    force_captions: yes
    number_sections: true
    theme: lumen
    toc: yes
    toc_float: yes
    df_print: paged
    # code_folding: "hide"
  pdf_document:
    fig_caption: yes
    force_captions: yes
    highlight: pyments
    keep_tex: yes
    latex_engine: xelatex
    number_sections: no
    toc: no
    
---

# Programming environment

```{r message=FALSE}
# various add-on scripts and stats tools
source("scripts/custom_tools.R")

library(tidyverse)
library(ggplot2) 
library(ggpubr) # ggplot extension
```

# Load data

## Load processed RDS / plate_collection data from temp_files

```{r warning=FALSE, echo = FALSE}
# point to parent data directory
setwd("temp_files/")
temp_data_storage <- "founders_quantal_processed.RData"
founders_quantal_collection <- readRDS(temp_data_storage)
```

# Data source construction

```{r}
selected_features <- c("h2axpositive_infocus",
                       "infocus_intensity_nucleus_alexa488_mean_mean",
                       "infocus_intensity_cell_hoechst_mean_stdev",
                       "infocus_cell_roundness_mean",
                       "infocus_cell_roundness_stdev",
                       "nuclei_numberofobjects",
                       "infocus_numberofobjects"
                       )
```

# Analysis

## Correlation analysis and Dimension Reduction

### Functions

```{r}
retrieve_feature_df_rescaled <- function(data, covariates){
  start_idx = grep("timepoint", colnames(data)) + 1
  end_idx = grep("number_of_analyzed_fields", colnames(data)) - 1
  all_features <- colnames(data[,start_idx:end_idx])
  data[,c(all_features)] <- lapply(data[,c(all_features)], function(x) scale(x, center = FALSE, scale = max(x, na.rm = TRUE)/100))
  return (data[,c(covariates,all_features)])
}

remove_sd_vars <- function(data){
  data <- dplyr::select(data, -dplyr::contains("stdev"))
  return (data)
}

mean_correlation_by_doseresponse <- function(data, group_id = 'strain', remove_outliers = TRUE){
  
  # hardcoded - need to improve
  dose_pairs <- as.data.frame(cbind(low=c(0,0.1,0.5,1,2,3,4), high=c(0.1,0.5,1,2,3,4,5)))
  
  mean_df_list <- list()
  stdev_df_list <- list()
  corr_dose_pair_df <- list()
    
  # loop through dose pairs
  for (i in 1:nrow(dose_pairs)){
    low <- dose_pairs[i, "low"]
    high  <- dose_pairs[i, "high"]
    print(paste("processing differences at", low,":",high, "at",group_id,"level"))
    
    sub_df_mean_diff_per_dose_response <- data %>%
      dplyr::filter(dose %in% c(low,high)) %>% # select only values inside low and high
      separate(mouse, c("strain","replicate")) %>% # extract specific - remove as is unnecessary
      group_by(strain, dose) %>%  # group by strain and dose - also unnecessary code
      summarise_each(funs(mean), -c(replicate)) %>% # mean of each strain per dose response change
      group_by(strain) %>%# now just group by strain
      summarise_at(vars(-dose),diff) # calculate difference in mean values
    
    sub_df_stdev_per_dose_response <- data %>%
      dplyr::filter(dose %in% c(low,high)) %>% # select only values inside low and high
      separate(mouse, c("strain","replicate")) %>% # fix
      group_by(strain) %>%  # group by strain 
      summarise_at(vars(-c(replicate, dose)),diff) %>%# get difference per dose pair within strain group
      group_by(strain) %>%
      summarise_each(funs(sd))
    
    # keep the first column 
    names <-  sub_df_mean_diff_per_dose_response$strain
    
    # Transpose everything other than the first column
    mean_T <- as.data.frame(as.matrix(t(sub_df_mean_diff_per_dose_response[,-1])))
    stdev_T <- as.data.frame(as.matrix(t(sub_df_stdev_per_dose_response[,-1])))
    
    # Assign first column as the column names of the transposed dataframe
    colnames(stdev_T) <- colnames(mean_T) <- names
    res2<-Hmisc::rcorr(as.matrix(t(mean_T)))
    ut <- upper.tri(res2$r)
    
    features_a <- rownames(res2$r)[row(res2$r)[ut]]
    features_b <- rownames(res2$r)[col(res2$r)[ut]]
    correlations <- (res2$r)[ut]
    
    flat_matrix_to_df <- data.frame(
      feature_a = features_a,
      feature_b = features_b,
      cor  = correlations
      )
    colnames(flat_matrix_to_df)[3] <- paste0("cor_",low,"_",high)
    
    # append DR matrix to sub list
    mean_df_list[[paste0("interval_",low,"_",high)]] <- res2$r
    stdev_df_list[[paste0("interval_",low,"_",high)]] <- as.matrix(stdev_T)
    corr_dose_pair_df[[paste0("interval_",low,"_",high)]] <- flat_matrix_to_df
  }
  # return all 3 sublists of matrices
  return (list("mean_corr_matrix_list" = mean_df_list,
               "mean_stdev_df_list" = stdev_df_list,
               "mean_corr_dosepair_df_list" = corr_dose_pair_df
               #"variance_matrices" = variance_matrix_list
               ))
}

extract_mean_stdev <- function(stdev_list, n = 'all'){
  # reduce all matrices into a single dataframe of average values
    stdev_reduced_df <- as.data.frame(Reduce("+",  lapply(stdev_list, function(x) replace(x, is.na(x), 0))) / length(lapply(stdev_list, Negate(is.na))))
    if (n == 'all'){
      n <- nrow(stdev_reduced_df)
    }
  stdev_reduced_df$sdmeans <- rowMeans(stdev_reduced_df)
  sub_stdev <- stdev_reduced_df %>% slice_max(sdmeans, n = n)
  return (sub_stdev)
}

extract_mean_corr <- function(corr_list){
  
  corr_reduced_matrix <- Reduce("+",  lapply(corr_list, function(x) replace(x, is.na(x), 0))) / length(lapply(corr_list, Negate(is.na)))

  #corr_reduced_df$corrmeans <- rowMeans(corr_reduced_df)
  return (corr_reduced_matrix)
  
}

remove_outliers <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.05, .95), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}

feature_exceedance_extraction <- function(dr_list_object, corr_cut_off = .99, n = 25){

  # use this again later to fill the void
  sub_stdev <- extract_mean_stdev(dr_list_object$mean_stdev_df_list, n)
  
  features <- data.frame("feature" = rownames(sub_stdev), "mean_sd" = sub_stdev$sdmeans)
    vals <- subset_corr_matrix(
      avg_corr_mat =  dr_list_object$mean_corr_matrix_list,
      avg_std_mat = sub_stdev,
      all_features = features,
      corr_cut_off = corr_cut_off)
    return(vals)
}

subset_corr_matrix <- function(avg_corr_mat, avg_std_mat, all_features, corr_cut_off){
  
    corr_df_mean_all <- as.data.frame(Reduce("+",  lapply(avg_corr_mat, function(x) replace(x, is.na(x), 0))) / length(lapply(avg_corr_mat, Negate(is.na))))
    
    # subset on all_features
    corr_df_mean_subset <- corr_df_mean_all[
      rownames(corr_df_mean_all) %in% all_features$feature, 
      colnames(corr_df_mean_all) %in% all_features$feature
      ] 
    
    m <- as.matrix(corr_df_mean_subset)
    
    # ought to change this to a range? eg c(-0.9:0.9)
    correlations <- which( abs(m) > corr_cut_off, arr.ind=T )
    vals <- correlations[correlations[, 1] != correlations[, 2], ]
    vals <- as.data.frame(cbind(vals,correlation=m[vals]))
    
    print(paste("identified",length(unique(vals$row)),"/",length(all_features$feature),"with one or more dose pair exceeding",corr_cut_off ))
  return(vals)
}

filter_exceedances <- function(list_data, n, corr_cut_off, rank_by){
  
  print(paste(n,"features to be evaluated by highest", rank_by))
  vals <- feature_exceedance_extraction(dr_list_object = list_data, corr_cut_off = corr_cut_off, n = n)
  vals$name <- gsub("\\..*","",rownames(vals))
  sub_stdev <- extract_mean_stdev(list_data$mean_stdev_df_list, n = n)
  sub_stdev$name <- rownames(sub_stdev)
  intersecting_features <- intersect(sub_stdev$name,vals$name)
  remove <- c()
  keep <- c()
  
  # start @ lowest stdev 
  for (i in 1:nrow(sub_stdev)){
    name <- gsub("\\..*","",sub_stdev[i,]$name)
    if (name %in% intersecting_features){
        f_corr_df <- vals[vals[,'name']==name,]
        f_corr_df_mirror <- vals[(vals[,'col'] ==  f_corr_df$row),]
        f_corr_all <- cbind(f_corr_df,f_corr_df_mirror)[,c(4,8,3)] %>% 
          left_join(sub_stdev, by = c("name" = "name")) %>%
          left_join(sub_stdev, by = c("name.1" = "name")) %>%
          select(contains(c("name","correlation","sdmeans"))) %>% 
          arrange(desc(abs(correlation)))
        for (r in 1:nrow(f_corr_all)){
            if (f_corr_all$sdmeans.x[r] >= f_corr_all$sdmeans.y[r]){
              if(f_corr_all$name.1[r] %in% remove){
              }else{
                remove <- c(remove,f_corr_all$name.1[r])
              }
            }else{
              if(f_corr_all$name[r]%in% remove){
              }else{
                remove <- c(remove,f_corr_all$name[r],)
              }
            }
        }
    }else{
    }
  }
  keep <- sub_stdev[sub_stdev$name %notin% remove,]
  remove <- sub_stdev[sub_stdev$name %in% remove,]
  print(paste("salvaging", nrow(keep),"/",n,"features"))
  return (list("keep"=keep,"remove"=remove))
}
```

### Reduction

1. Remove stdev columns

2. rescale predictors between 0 and 100

3. _mean_correlation_by_dose_response_ takes harmony input and calculates
  - mean_corr_matrix_list, a list of correlation matrices per dose response (update this)
  - mean_stdev_df_list, a list of stdev dataframes for each strain
  - mean_corr_dosepair_df_list, a list of pairwise correlations between each feature
  
4. _filter_exceedances_ takes the result of the prior function, takes parameters to decide which features are to be selected

```{r}
############ 1 ############
founders_quantal_collection$all_plates <- remove_sd_vars(founders_quantal_collection$all_plates)

############ 2 ############
rescaled_data <- retrieve_feature_df_rescaled(founders_quantal_collection$all_plates, covariates = c("dose","mouse") )

############ 3 ############
mouse_data_metrics <- mean_correlation_by_doseresponse(data = rescaled_data, 
                                                       remove_outliers = TRUE, # currently does this by default
                                                       group_id = 'mouse')

############ 4 ############
corr_threshold <- 1
results <- suppressWarnings(filter_exceedances(list_data = mouse_data_metrics, # input list object
                                               n = 16, # maximum number of values to return
                                               corr_cut_off = corr_threshold, # makes underlying values positive
                                               rank_by = 'stdev') # this is the only option...
                            ) 
```

```{r}
corr_matrix <- extract_mean_corr(mouse_data_metrics$mean_corr_matrix_list)
subset_corr_matrix_data <- corr_matrix[results$keep$name,results$keep$name]
heatmap(subset_corr_matrix_data, main = paste("Subset of features on abs-value corr value",corr_threshold))
```

```{r}
# vals <- feature_exceedance_extraction(dr_list_object = mouse_data_metrics, corr_cut_off = 0.5, n = 15)
# vals$name <- gsub("\\..*","",rownames(vals))

#sub_stdev <- extract_mean_stdev(mouse_data_metrics$mean_stdev_df_list, n = 'all')
corr_matrix <- extract_mean_corr(mouse_data_metrics$mean_corr_matrix_list)
subset_corr_matrix_data <- corr_matrix[results$keep$name,results$keep$name]
#subset_stdev<- subset(sub_stdev, rownames(sub_stdev) %in% results$keep$name)
#equivalency_matrix <- (corr_matrix ==  1)

# append_back_to_featuresdf <- function()
# 
# reduced_corr_matrix <- function(m){
# 
#   negative_correlation <- (m < 0)
#   positive_correlation <- (m >= 0)
#   nx <- ny <- nrow(m)
#   
#   makeRects <- function(tfMat,border){
#     cAbove = expand.grid(1:nx,1:ny)[tfMat,]
#     xl=cAbove[,1]-0.49
#     yb=cAbove[,2]-0.49
#     xr=cAbove[,1]+0.49
#     yt=cAbove[,2]+0.49
#     rect(xl,yb,xr,yt,border=border,lwd=2)
#   }
#   heatmap(t(m),Rowv = NA, Colv=NA, add.expr = {
#    makeRects(negative_correlation,"red"); makeRects(positive_correlation,"green")})
# }
# 
# reduced_corr_matrix(corr_matrix[results$keep$name,results$keep$name])
#  exact_correlation <- corr_matrix[(corr_matrix %in% c(-1,1))]
# reduced_corr_matrix(exact_correlation)
```

## Save/overwrite RDS

```{r}
temp_data_storage <- paste0("temp_files/founders_quantal_reduced.RData")
saveRDS(founders_quantal_collection, temp_data_storage)
```

