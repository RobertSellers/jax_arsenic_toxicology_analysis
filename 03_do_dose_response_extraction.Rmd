---
title: "DO #3 Dose-response extraction"
author:
- name: Robert Sellers
  affiliation: The Jackson Laboratory
date: "`r paste('Last knit on:',format(Sys.time(), '%d %B %Y'))`"
abstract: |
latex_engine: pdflatex
output:
  html_document:
    fig_caption: yes
    force_captions: yes
    number_sections: true
    theme: lumen
    toc: yes
    toc_float: yes
    df_print: paged
    # code_folding: "hide"
  pdf_document:
    fig_caption: yes
    force_captions: yes
    highlight: pyments
    keep_tex: yes
    latex_engine: xelatex
    number_sections: no
    toc: no
    
---

# Programming environment

```{r message=FALSE}
# various add-on scripts and stats tools
source("scripts/custom_tools.R")

library(tidyverse)
library(drc) # dose response library
library(nlme) # mixed effects library
library(medrc) # drc + medrc wrapper
library(ggplot2) 
library(ggpubr) # ggplot extension
library(foreach)
library(doSNOW)
library(futile.logger)
```

# Load data

## Load processed RDS / plate_collection data from temp_files

```{r warning=FALSE, echo = FALSE}
# point to parent data directory
setwd("temp_files/")
temp_data_storage <- "do_focus_reduced.RData"
harmony_collection <- readRDS(temp_data_storage)
```

# Instructions accumulation

- Code to maintain distribution / effects / model selection choices

```{r}
instructions_df <- data.frame(matrix(ncol=10, nrow=nrow(harmony_collection$features_df), dimnames=list(NULL, c("name", "model", "log_transform","zero_replace","scale_positive","rescale_0_100","skip","formula","weight_var","rename"))))
rownames(instructions_df) <- instructions_df$name <- harmony_collection$features_df$name_

instructions_df <- instructions_df %>%
  replace_na(list(log_transform = FALSE, zero_replace = FALSE, scale_positive=FALSE))

update_instructions <- function(df, instructions_df){
  match_arr <- match(instructions_df$name, df$name_)
  instructions_df$model <- df$model[match_arr]
  instructions_df$log_transform <- df$log_transform[match_arr]
  instructions_df$zero_replace <- df$zero_replace[match_arr]
  instructions_df$scale_positive <- df$scale_positive[match_arr]
  instructions_df$rescale_0_100 <- df$rescale_0_100[match_arr]
  instructions_df$formula <- df$formula[match_arr]
  instructions_df$skip <- df$skip[match_arr]
  instructions_df$weight_var <- df$weight_var[match_arr]
  instructions_df$rename <- df$rename[match_arr]
  return (instructions_df)
}

```

## Additional update instructions

### Select subset

```{r}
# isolate features based on whatever criteria
feature_selection <- harmony_collection$features_df$name[harmony_collection$features_df$custom_selection==TRUE]
```

### DRC instructions

```{r}
# values based on sd reduction
update_df = data.frame(
  name_ = c("infocus_numberofobjects" ,"infocus_intensity_nucleus_alexa488_mean_mean"     
,"infocus_cell_roundness_mean"   
,"nuclei_numberofobjects"   
,"h2axpositive_infocus"), 
  model = rep(NA, length(feature_selection)),
  log_transform = c(TRUE),
  zero_replace = c(FALSE),
  scale_positive = c(FALSE),
  rescale_0_100 = c(FALSE),
  skip = c(FALSE),
  formula = c("LL.4"),
  weight_var = rep(NA, length(feature_selection)),
  rename = rep(NA, length(feature_selection)),
  skip = c(FALSE,TRUE,TRUE,TRUE,TRUE)
  )

# update 
instructions_df <- update_instructions(update_df, instructions_df)
```

# DRC extraction

## Functions

```{r}
log_skew_transform <- function(response_var) {
  skew_val <- e1071::skewness(response_var)
  skew.score <- function(c, x)
    (e1071::skewness(log(x + c))) ^ 2
  if (!is.na(skew_val)) {
    print(paste0("performing log transformation with skew:", skew_val))
    best.c <- optimise(skew.score, c(0, 1), x = response_var)$minimum
    response_var <- log(response_var + best.c)
  } else{
    print("No optimization possible")
    # to be continued
    response_var <- response_var
    #df$response <- log(df$response)
  }
  return(response_var)
}

modify_feature_v2 <- function(feature, lookup_, data){
  data<- harmony_collection$all_plates
  data <- data %>%
    #stats::na.omit() %>% 
    dplyr::mutate(sex = as.factor(sex),
          dose = as.numeric(as.character(dose))) %>%
    dplyr::select_(.dots = 
                     list(response = feature, 
                          dose = 'dose', 
                          plate = 'plate', 
                          sex = 'sex', 
                          individual = 'individual',
                          mouse = 'mouse')
                   )
  if (lookup_$log_transform) {
    data$response <- log_skew_transform(data$response)
  }

  if (lookup_$scale_positive){
    # rescale data between 0 and 1
    new_max = abs(min(data$response))+0.001
    print(paste("scaling to 0 and",new_max))
    data$response <- scales::rescale(data$response,to = c(0,new_max), finite=TRUE, na.rm=TRUE)
  } 
  if (lookup_$zero_replace){
    print("replacing zero with 0.0001")
    data$response[data$response == 0] <- 0.0001
  }
  if(lookup_$rescale_0_100){
    print("rescaling the data")
      data$response <- scales::rescale(data$response,to = c(0.0001,99.999))
  }
  return (data)
}
```


## Setting up feature instructions

```{r}
# set up controls and structure
#https://www.rdocumentation.org/packages/drc/versions/2.5-12/topics/LL.4
#http://search.r-project.org/library/drc/html/W4.html
fcts <-  list("LL.4" = LL.4(names = c("slope", "min_value", "max_value", "ec_50")), # is ec50
              "W1.4" = W1.4(names = c("slope", "min_value", "max_value", "ec_50")), # not ec50
              "W2.4" = W2.4(names = c("slope", "min_value", "max_value", "ec_50"))) # not ec50

group_names <- unique(as.character(harmony_collection$all_plates$individual))
temp_df <- data.frame(matrix(ncol = (length(group_names) + 2), nrow = 0))
colnames(temp_df) <- c("name", "aic", group_names)
```

### Apply instructions to selected feature list

```{r}
transformed_data_list <- list()
corresponding_model_list <- list()
coef_list <- list()
ed_list <- list()

# will only apply transformations to those data that exist in instructions
for (feature in feature_selection){
  print(feature)
  # generate modified distributions from feature subset
  if(!instructions_df[feature,]$skip){
    data <- modify_feature_v2(
      feature = feature,
      lookup = instructions_df[feature,],
      data = harmony_collection$all_plates
    )
    summary(data$response)
    formula_ <- instructions_df[feature,]$formula
    hist(data$response,breaks=30, main = feature)

    # creates a 
     m <- lapply(1: length(split(data, data$individual)), function(i){
       drc::drm(response ~ dose,
        data = dat_list[[i]],
        #curveid = factor(individual),
        na.action = na.omit,
        fct = fcts[formula_][[1]])
       })

    # ed_obj <- ED(m, c(5,10,20,50,75,90), 
    #              interval="fls",
    #              type = "relative", 
    #              display = FALSE
    #              )
    # 
    # coef_df <- as.data.frame(coef(summary(m)))
    # transformed_data_list[[feature]] <- data
    # corresponding_model_list[[feature]] <- m
    # coef_list[[feature]]<- coef_df
    # ed_list[[feature]] <- ed_obj
  }
}
```

# Generate DRC curves within nested cluster

- consider https://stackoverflow.com/questions/19791609/saving-multiple-outputs-of-foreach-dopar-loop for improvements
- consider this library https://www.bioconductor.org/packages/release/bioc/vignettes/GRmetrics/inst/doc/GRmetrics-vignette.html

```{r}
# # isolate features based on whatever criteria

#consider https://rpubs.com/palday/mixed-interactions
cl <- suppressWarnings(snow::makeCluster(12, type="SOCK")) # for 12 cores machine
# flog.threshold(DEBUG) 
# check out https://github.com/zatonovo/futile.logger
suppressWarnings(doSNOW::registerDoSNOW (cl))

system.time({
    # generate outer cluster around features
    # this controls row generation
    # you must pass required libraries inside 
    cluster_results_df <- foreach (f_ = feature_selection, .combine = 'rbind') %:% 
      
      # generate inner cluster around formulas
      # this controls column generation
      foreach (formula_ = fcts, .combine = 'cbind', .inorder = FALSE, 
               .packages = c("drc", "nlme", "tidyverse","stats")) %dopar%  {
        tryCatch(

            expr = {
              # flog.debug('Doing some stuff with %s', f_)                                           
              # look up response transformation instructions
              data <- modify_feature_v2(
                response_var = f_,
                lookup = instructions_df[c(f_),],
                data = founders_quantal_collection$all_plates
                )

               m <- drc::drm(response ~ dose, 
                data = data,
                curveid = individual,
                type = 'continuous',
                fct = formula_)
  
                coefs <- m$coefficients
                aic_value <- AIC(m)
                # also get log likelihood
                # all EC values
                temp_df[1,] <- c(f_, aic_value, tail(coefs, n = length(group_names)))
                # writeLines("\nmodel instructions succeeded\n")
                temp_df
            },
            error = function(e){
              # writeLines("\nmodel instructions failed\n")
              temp_df[1,] <- c(f_, NA, rep(NA, length(group_names)))
              temp_df
            }
        )
        
      }
    cluster_results_df
})
stopCluster(cl)
```

```{r}
# testing

lookup_ <- instructions_df[c('h2axpositive_infocus'),]
data <- modify_feature_v2(lookup = instructions_df[c('h2axpositive_infocus'),],
                       data = founders_quantal_collection$all_plates)
              
```

## evaluation of models

```{r}
bulk_evaluation <- function(results){
  avg_aic <- mean(na.omit(as.numeric(results$aic)))
  # AIC as estimation error / lower is better
  print(paste("avg AIC value:", avg_aic))
  na_count <- sum(is.na(results[,3])) / nrow(results)
  print(paste("PCT missing:",percent(na_count)))

}

# quick mod
# should consider moving this code to the cluster
name_idx <- grep("name", colnames(cluster_results_df))

clusters_split<- list(cluster_results_df[, name_idx[1]:10], cluster_results_df[, name_idx[2]:20], cluster_results_df[, name_idx[3]:30])
names(clusters_split)<-c(fcts[[1]]$name,fcts[[2]]$name,fcts[[3]]$name)


bulk_evaluation(clusters_split$LL.4)
bulk_evaluation(clusters_split$W1.4)
bulk_evaluation(clusters_split$W2.4)
```

## Save/overwrite RDS

```{r}
# temp_data_storage <- paste0("temp_files/founders_quantal_reduced.RData")
# saveRDS(founders_quantal_collection, temp_data_storage)
```

